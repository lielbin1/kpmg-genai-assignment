import os
import json
import numpy as np
from openai import AzureOpenAI
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity

# Load .env variables
load_dotenv()
AZURE_API_KEY = os.getenv("AZURE_OPENAI_KEY")
AZURE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
DEPLOYMENT_NAME = "text-embedding-ada-002"

# Init Azure OpenAI client
client = AzureOpenAI(
    api_key=AZURE_API_KEY,
    api_version="2024-02-01",
    azure_endpoint=AZURE_ENDPOINT
)

def get_embedding(text):
    response = client.embeddings.create(
        model=DEPLOYMENT_NAME,
        input=[text]
    )
    return response.data[0].embedding

def load_all_embeddings(folder):
    all_chunks = []
    for root, _, files in os.walk(folder):
        for file in files:
            if file.endswith(".json"):
                path = os.path.join(root, file)
                with open(path, encoding="utf-8") as f:
                    data = json.load(f)
                    all_chunks.extend(data)
    return all_chunks

def find_top_k_matches(question, all_chunks, k=5):
    question_vec = np.array(get_embedding(question)).reshape(1, -1)
    
    seen = set()
    scores = []

    for chunk in all_chunks:
        key = (chunk["text"], chunk["source"]) 
        if key in seen:
            continue
        seen.add(key)

        doc_vec = np.array(chunk["embedding"]).reshape(1, -1)
        score = cosine_similarity(question_vec, doc_vec)[0][0]
        scores.append((score, chunk["text"], chunk["source"]))

    top = sorted(scores, key=lambda x: x[0], reverse=True)[:k]
    return top


def main():
    user_question = "  砖 驻 砖专砖?"
    
    user_profile = {
        "first_name": "",
        "last_name": "",
        "id_number": "444444444",
        "gender": "砖",
        "age": 4,
        "hmo": "",
        "card_number": "444444444",
        "membership_tier": ""
    }

    # 住 转 砖  注 拽砖专 砖   砖驻专 转 转
    user_context = (
        f"砖 驻专: {user_profile['first_name']}, "
        f"砖 砖驻: {user_profile['last_name']}, "
        f"转注转 转: {user_profile['id_number']}, "
        f": {user_profile['gender']}, "
        f": {user_profile['age']}, "
        f"拽驻转 : {user_profile['hmo']}, "
        f"住驻专 专住: {user_profile['card_number']}, "
        f"住 专转: {user_profile['membership_tier']}"
    )

    full_query = f"{user_question} {user_profile['hmo']} {user_profile['membership_tier']}"


    all_chunks = load_all_embeddings("phase2_embedding")

    found = [chunk for chunk in all_chunks if "驻 砖专砖 /  / " in chunk["text"]]
    for i, chunk in enumerate(found):
        print(f"\n 拽专: {chunk['source']}")
        print(f" 拽住: {chunk['text']}")
    

    top_chunks = find_top_k_matches(full_query, all_chunks, k=10)

    print("\n 转爪转  专转 砖:")
    for score, text, source in top_chunks:
        print(f"\n 拽专: {source}")
        print(f" : {score:.4f}")
        print(f" 拽住: {text}")


if __name__ == "__main__":
    main()
